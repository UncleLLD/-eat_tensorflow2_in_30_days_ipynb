{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-4 使用多GPU训练模型\n",
    "如果使用多GPU训练模型，推荐使用内置fit方法，较为方便，仅需添加2行代码。\n",
    "\n",
    "在Colab笔记本中：修改->笔记本设置->硬件加速器 中选择 GPU\n",
    "\n",
    "注：以下代码只能在Colab 上才能正确执行。\n",
    "\n",
    "可通过以下colab链接测试效果《tf_多GPU》：\n",
    "\n",
    "https://colab.research.google.com/drive/1j2kp_t0S_cofExSN7IyJ4QtMscbVlXU-\n",
    "\n",
    "MirroredStrategy过程简介：\n",
    "训练开始前，该策略在所有 N 个计算设备上均各复制一份完整的模型；\n",
    "每次训练传入一个批次的数据时，将数据分成 N 份，分别传入 N 个计算设备（即数据并行）；\n",
    "N 个计算设备使用本地变量（镜像变量）分别计算自己所获得的部分数据的梯度；\n",
    "使用分布式计算的 All-reduce 操作，在计算设备间高效交换梯度数据并进行求和，使得最终每个设备都有了所有设备的梯度之和；\n",
    "使用梯度求和的结果更新本地变量（镜像变量）；\n",
    "当所有设备均更新本地变量后，进行下一轮训练（即该并行策略是同步的）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#此处在colab上使用1个GPU模拟出两个逻辑GPU进行多GPU训练\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # 设置两个逻辑GPU模拟多GPU训练\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024),\n",
    "             tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一，准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 300\n",
    "BATCH_SIZE = 32\n",
    "(x_train,y_train),(x_test,y_test) = datasets.reuters.load_data()\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train,maxlen=MAX_LEN)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_LEN)\n",
    "\n",
    "MAX_WORDS = x_train.max()+1\n",
    "CAT_NUM = y_train.max()+1\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)) \\\n",
    "          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n",
    "          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n",
    "\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) \\\n",
    "          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n",
    "          .prefetch(tf.data.experimental.AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二，定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "def create_model():\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n",
    "    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n",
    "    return(model)\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(optimizer=optimizers.Nadam(),\n",
    "                loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[metrics.SparseCategoricalAccuracy(),metrics.SparseTopKCategoricalAccuracy(5)]) \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三，训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0422 23:28:07.921303 4403842496 cross_device_ops.py:1258] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 7)            216874    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 296, 64)           2304      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 148, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 146, 32)           6176      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 73, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2336)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 46)                107502    \n",
      "=================================================================\n",
      "Total params: 332,856\n",
      "Trainable params: 332,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 281 steps, validate for 71 steps\n",
      "Epoch 1/10\n",
      "281/281 [==============================] - 15s 52ms/step - loss: 3.4311 - sparse_categorical_accuracy: 0.4470 - sparse_top_k_categorical_accuracy: 0.7212 - val_loss: 3.3308 - val_sparse_categorical_accuracy: 0.5325 - val_sparse_top_k_categorical_accuracy: 0.7159\n",
      "Epoch 2/10\n",
      "281/281 [==============================] - 12s 43ms/step - loss: 3.3290 - sparse_categorical_accuracy: 0.5366 - sparse_top_k_categorical_accuracy: 0.7236 - val_loss: 3.3230 - val_sparse_categorical_accuracy: 0.5396 - val_sparse_top_k_categorical_accuracy: 0.7128\n",
      "Epoch 3/10\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 3.3166 - sparse_categorical_accuracy: 0.5490 - sparse_top_k_categorical_accuracy: 0.7221 - val_loss: 3.3254 - val_sparse_categorical_accuracy: 0.5374 - val_sparse_top_k_categorical_accuracy: 0.7115\n",
      "Epoch 4/10\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 3.3011 - sparse_categorical_accuracy: 0.5686 - sparse_top_k_categorical_accuracy: 0.7219 - val_loss: 3.3186 - val_sparse_categorical_accuracy: 0.5427 - val_sparse_top_k_categorical_accuracy: 0.7110\n",
      "Epoch 5/10\n",
      "281/281 [==============================] - 8s 27ms/step - loss: 3.2815 - sparse_categorical_accuracy: 0.5852 - sparse_top_k_categorical_accuracy: 0.7233 - val_loss: 3.3108 - val_sparse_categorical_accuracy: 0.5525 - val_sparse_top_k_categorical_accuracy: 0.7168\n",
      "Epoch 6/10\n",
      "281/281 [==============================] - 9s 31ms/step - loss: 3.2679 - sparse_categorical_accuracy: 0.5984 - sparse_top_k_categorical_accuracy: 0.7255 - val_loss: 3.3130 - val_sparse_categorical_accuracy: 0.5499 - val_sparse_top_k_categorical_accuracy: 0.7155\n",
      "Epoch 7/10\n",
      "281/281 [==============================] - 14s 49ms/step - loss: 3.2625 - sparse_categorical_accuracy: 0.6031 - sparse_top_k_categorical_accuracy: 0.7272 - val_loss: 3.3040 - val_sparse_categorical_accuracy: 0.5601 - val_sparse_top_k_categorical_accuracy: 0.7195\n",
      "Epoch 8/10\n",
      "281/281 [==============================] - 10s 36ms/step - loss: 3.2582 - sparse_categorical_accuracy: 0.6070 - sparse_top_k_categorical_accuracy: 0.7287 - val_loss: 3.3009 - val_sparse_categorical_accuracy: 0.5623 - val_sparse_top_k_categorical_accuracy: 0.7195\n",
      "Epoch 9/10\n",
      "281/281 [==============================] - 10s 36ms/step - loss: 3.2569 - sparse_categorical_accuracy: 0.6083 - sparse_top_k_categorical_accuracy: 0.7292 - val_loss: 3.3009 - val_sparse_categorical_accuracy: 0.5614 - val_sparse_top_k_categorical_accuracy: 0.7191\n",
      "Epoch 10/10\n",
      "281/281 [==============================] - 11s 39ms/step - loss: 3.2559 - sparse_categorical_accuracy: 0.6089 - sparse_top_k_categorical_accuracy: 0.7317 - val_loss: 3.3070 - val_sparse_categorical_accuracy: 0.5548 - val_sparse_top_k_categorical_accuracy: 0.7213\n"
     ]
    }
   ],
   "source": [
    "#增加以下两行代码\n",
    "strategy = tf.distribute.MirroredStrategy()  \n",
    "with strategy.scope(): \n",
    "    model = create_model()\n",
    "    model.summary()\n",
    "    model = compile_model(model)\n",
    "\n",
    "history = model.fit(ds_train,validation_data = ds_test,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

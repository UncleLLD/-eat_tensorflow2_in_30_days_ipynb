{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-7 使用spark-scala调用tensorflow2.0训练好的模型\n",
    "本篇文章介绍在spark中调用训练好的tensorflow模型进行预测的方法。\n",
    "\n",
    "本文内容的学习需要一定的spark和scala基础。\n",
    "\n",
    "如果使用pyspark的话会比较简单，只需要在每个excutor上用Python加载模型分别预测就可以了。\n",
    "\n",
    "但工程上为了性能考虑，通常使用的是scala版本的spark。\n",
    "\n",
    "本篇文章我们通过TensorFlow for Java 在spark中调用训练好的tensorflow模型。\n",
    "\n",
    "利用spark的分布式计算能力，从而可以让训练好的tensorflow模型在成百上千的机器上分布式并行执行模型推断。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 〇，spark-scala调用tensorflow模型概述\n",
    "在spark(scala)中调用tensorflow模型进行预测需要完成以下几个步骤。\n",
    "\n",
    "（1）准备protobuf模型文件\n",
    "\n",
    "（2）创建spark(scala)项目，在项目中添加java版本的tensorflow对应的jar包依赖\n",
    "\n",
    "（3）在spark(scala)项目中driver端加载tensorflow模型调试成功\n",
    "\n",
    "（4）在spark(scala)项目中通过RDD在excutor上加载tensorflow模型调试成功\n",
    "\n",
    "（5） 在spark(scala)项目中通过DataFrame在excutor上加载tensorflow模型调试成功"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一，准备protobuf模型文件\n",
    "我们使用tf.keras 训练一个简单的线性回归模型，并保存成protobuf文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 800 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 1s 1ms/sample - loss: 194.2585 - mae: 11.9687\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s 178us/sample - loss: 179.9152 - mae: 11.5112\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 166.0658 - mae: 11.0498\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s 391us/sample - loss: 152.3754 - mae: 10.5779\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 372us/sample - loss: 139.4555 - mae: 10.1163\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s 299us/sample - loss: 127.3244 - mae: 9.6567\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 115.6854 - mae: 9.1976\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 228us/sample - loss: 104.6877 - mae: 8.7413\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s 219us/sample - loss: 94.3886 - mae: 8.2894\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s 394us/sample - loss: 84.6295 - mae: 7.8426\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 187us/sample - loss: 75.2697 - mae: 7.3866\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 66.6588 - mae: 6.9383\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s 203us/sample - loss: 58.7371 - mae: 6.4969\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 51.2107 - mae: 6.0542\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s 191us/sample - loss: 44.3295 - mae: 5.6162\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s 165us/sample - loss: 37.9035 - mae: 5.1769\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 32.2225 - mae: 4.7510\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 27.1521 - mae: 4.3285\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 22.4648 - mae: 3.9201\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 18.4171 - mae: 3.5261\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 15.0428 - mae: 3.1690\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 12.2577 - mae: 2.8450\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s 219us/sample - loss: 10.0427 - mae: 2.5537\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s 267us/sample - loss: 8.3741 - mae: 2.3123\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s 241us/sample - loss: 7.1835 - mae: 2.1375\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s 163us/sample - loss: 6.4238 - mae: 2.0125\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s 303us/sample - loss: 5.9488 - mae: 1.9393\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 285us/sample - loss: 5.6258 - mae: 1.8841\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 5.3752 - mae: 1.8402\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 323us/sample - loss: 5.1698 - mae: 1.8021\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 322us/sample - loss: 4.9784 - mae: 1.7651\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 4.8078 - mae: 1.7340\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s 276us/sample - loss: 4.6521 - mae: 1.7024\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 216us/sample - loss: 4.5152 - mae: 1.6760\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 221us/sample - loss: 4.3985 - mae: 1.6550\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 196us/sample - loss: 4.3006 - mae: 1.6394\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 4.2124 - mae: 1.6232\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 228us/sample - loss: 4.1383 - mae: 1.6092\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s 173us/sample - loss: 4.0721 - mae: 1.5981\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s 233us/sample - loss: 4.0176 - mae: 1.5896\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s 225us/sample - loss: 3.9757 - mae: 1.5839\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s 207us/sample - loss: 3.9420 - mae: 1.5783\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 183us/sample - loss: 3.9155 - mae: 1.5744\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 178us/sample - loss: 3.8960 - mae: 1.5714\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 3.8773 - mae: 1.5674\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 230us/sample - loss: 3.8656 - mae: 1.5645\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 178us/sample - loss: 3.8534 - mae: 1.5642\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s 233us/sample - loss: 3.8461 - mae: 1.5630\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 3.8414 - mae: 1.5618\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 214us/sample - loss: 3.8348 - mae: 1.5612\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 3.8330 - mae: 1.5604\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 180us/sample - loss: 3.8292 - mae: 1.5603\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 245us/sample - loss: 3.8282 - mae: 1.5610\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 164us/sample - loss: 3.8264 - mae: 1.5613\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 176us/sample - loss: 3.8249 - mae: 1.5607\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 3.8237 - mae: 1.5603\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 0s 214us/sample - loss: 3.8244 - mae: 1.5612\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s 192us/sample - loss: 3.8238 - mae: 1.5610\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 3.8206 - mae: 1.5594\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 214us/sample - loss: 3.8214 - mae: 1.5607\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 3.8190 - mae: 1.5590\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 3.8225 - mae: 1.5616\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 163us/sample - loss: 3.8226 - mae: 1.5601\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 163us/sample - loss: 3.8222 - mae: 1.5608\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 3.8203 - mae: 1.5583\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 273us/sample - loss: 3.8221 - mae: 1.5610\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 220us/sample - loss: 3.8230 - mae: 1.5600\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s 180us/sample - loss: 3.8213 - mae: 1.5613\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 197us/sample - loss: 3.8212 - mae: 1.5609\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 279us/sample - loss: 3.8204 - mae: 1.5601\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 305us/sample - loss: 3.8220 - mae: 1.5622\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 190us/sample - loss: 3.8220 - mae: 1.5601\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s 213us/sample - loss: 3.8229 - mae: 1.5617\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 187us/sample - loss: 3.8209 - mae: 1.5606\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 313us/sample - loss: 3.8221 - mae: 1.5608\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 182us/sample - loss: 3.8210 - mae: 1.5617\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 215us/sample - loss: 3.8222 - mae: 1.5604\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 192us/sample - loss: 3.8221 - mae: 1.5613\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s 184us/sample - loss: 3.8220 - mae: 1.5611\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 214us/sample - loss: 3.8217 - mae: 1.5608\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s 212us/sample - loss: 3.8216 - mae: 1.5614\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s 187us/sample - loss: 3.8212 - mae: 1.5614\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 0s 213us/sample - loss: 3.8219 - mae: 1.5609\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 0s 169us/sample - loss: 3.8215 - mae: 1.5607\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 3.8212 - mae: 1.5606\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s 173us/sample - loss: 3.8193 - mae: 1.5590\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 3.8223 - mae: 1.5609\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 3.8214 - mae: 1.5609\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 389us/sample - loss: 3.8227 - mae: 1.5613s - loss: 3.8599 - mae: 1.569\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 285us/sample - loss: 3.8223 - mae: 1.5620\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 185us/sample - loss: 3.8206 - mae: 1.5602\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 183us/sample - loss: 3.8214 - mae: 1.5615\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 312us/sample - loss: 3.8223 - mae: 1.5606\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 227us/sample - loss: 3.8219 - mae: 1.5608\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 211us/sample - loss: 3.8222 - mae: 1.5615\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 193us/sample - loss: 3.8209 - mae: 1.5607\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 176us/sample - loss: 3.8217 - mae: 1.5611\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 180us/sample - loss: 3.8217 - mae: 1.5614\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 3.8225 - mae: 1.5615\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 213us/sample - loss: 3.8235 - mae: 1.5613\n",
      "w =  [[1.9827112]\n",
      " [-1.00276351]]\n",
      "b =  [2.97487545]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0423 00:08:28.954216 4365151680 deprecation.py:506] From /Users/ting/Library/Python/3.7/lib/python/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models,layers,optimizers\n",
    "\n",
    "## 样本数量\n",
    "n = 800\n",
    "\n",
    "## 生成测试用数据集\n",
    "X = tf.random.uniform([n,2],minval=-10,maxval=10) \n",
    "w0 = tf.constant([[2.0],[-1.0]])\n",
    "b0 = tf.constant(3.0)\n",
    "\n",
    "Y = X@w0 + b0 + tf.random.normal([n,1],mean = 0.0,stddev= 2.0)  # @表示矩阵乘法,增加正态扰动\n",
    "\n",
    "## 建立模型\n",
    "tf.keras.backend.clear_session()\n",
    "inputs = layers.Input(shape = (2,),name =\"inputs\") #设置输入名字为inputs\n",
    "outputs = layers.Dense(1, name = \"outputs\")(inputs) #设置输出名字为outputs\n",
    "linear = models.Model(inputs = inputs,outputs = outputs)\n",
    "linear.summary()\n",
    "\n",
    "## 使用fit方法进行训练\n",
    "linear.compile(optimizer=\"rmsprop\",loss=\"mse\",metrics=[\"mae\"])\n",
    "linear.fit(X,Y,batch_size = 8,epochs = 100)  \n",
    "\n",
    "tf.print(\"w = \",linear.layers[1].kernel)\n",
    "tf.print(\"b = \",linear.layers[1].bias)\n",
    "\n",
    "## 将模型保存成pb格式文件\n",
    "export_path = \"../data/linear_model/\"\n",
    "version = \"1\"       #后续可以通过版本号进行模型版本迭代与管理\n",
    "linear.save(export_path+version, save_format=\"tf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets\tsaved_model.pb\tvariables\r\n"
     ]
    }
   ],
   "source": [
    "!ls {export_path+version}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['inputs'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 2)\n",
      "        name: serving_default_inputs:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['outputs'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0423 00:09:25.968805 4616895936 deprecation.py:506] From /Users/ting/Library/Python/3.7/lib/python/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "# 查看模型文件相关信息\n",
    "!saved_model_cli show --dir {export_path+str(version)} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二，创建spark(scala)项目，在项目中添加java版本的tensorflow对应的jar包依赖"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 如果使用maven管理项目，需要添加如下 jar包依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-4a6e734c6a2b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-4a6e734c6a2b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <!-- https://mvnrepository.com/artifact/org.tensorflow/tensorflow -->\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<!-- https://mvnrepository.com/artifact/org.tensorflow/tensorflow -->\n",
    "<dependency>\n",
    "    <groupId>org.tensorflow</groupId>\n",
    "    <artifactId>tensorflow</artifactId>\n",
    "    <version>1.15.0</version>\n",
    "</dependency>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以从下面网址中直接下载 org.tensorflow.tensorflow的jar包\n",
    "\n",
    "以及其依赖的org.tensorflow.libtensorflow 和 org.tensorflowlibtensorflow_jni的jar包 放到项目中。\n",
    "\n",
    "https://mvnrepository.com/artifact/org.tensorflow/tensorflow/1.15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三， 在spark(scala)项目中driver端加载tensorflow模型调试成功\n",
    "我们的示范代码在jupyter notebook中进行演示，需要安装toree以支持spark(scala)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-765bce07b38f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-765bce07b38f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    import org.{tensorflow=>tf}\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import scala.collection.mutable.WrappedArray\n",
    "import org.{tensorflow=>tf}\n",
    "\n",
    "//注：load函数的第二个参数一般都是“serve”，可以从模型文件相关信息中找到\n",
    "\n",
    "val bundle = tf.SavedModelBundle \n",
    "   .load(\"/Users/liangyun/CodeFiles/eat_tensorflow2_in_30_days/data/linear_model/1\",\"serve\")\n",
    "\n",
    "//注：在java版本的tensorflow中还是类似tensorflow1.0中静态计算图的模式，需要建立Session, 指定feed的数据和fetch的结果, 然后 run.\n",
    "//注：如果有多个数据需要喂入，可以连续用用多个feed方法\n",
    "//注：输入必须是float类型\n",
    "\n",
    "val sess = bundle.session()\n",
    "val x = tf.Tensor.create(Array(Array(1.0f,2.0f),Array(2.0f,3.0f)))\n",
    "val y =  sess.runner().feed(\"serving_default_inputs:0\", x)\n",
    "         .fetch(\"StatefulPartitionedCall:0\").run().get(0)\n",
    "\n",
    "val result = Array.ofDim[Float](y.shape()(0).toInt,y.shape()(1).toInt)\n",
    "y.copyTo(result)\n",
    "\n",
    "if(x != null) x.close()\n",
    "if(y != null) y.close()\n",
    "if(sess != null) sess.close()\n",
    "if(bundle != null) bundle.close()  \n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四，在spark(scala)项目中通过RDD在excutor上加载tensorflow模型调试成功\n",
    "下面我们通过广播机制将Driver端加载的TensorFlow模型传递到各个excutor上，并在excutor上分布式地调用模型进行推断。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
